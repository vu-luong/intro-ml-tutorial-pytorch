{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xây dựng mô hình Neural Network\n",
    "\n",
    "- Mục tiêu: xây dựng mô hình Neural Network để phân loại ảnh cho bộ dữ liệu FashionMNIST.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPU hay CPU\n",
    "- Kiểm tra máy có GPU để tăng tốc huấn luyện không, nếu không có thì dùng CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# INSERT CODE HERE\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tóm tắt lý thuyết\n",
    "- Cần: $ f(x) \\rightarrow y $, $ x $ là input ảnh $28\\times28$, $ y $ là output nhãn lớp.\n",
    "- Min khoảng cách $ D(f(x), y) $\n",
    "- Neural Network là một cách biểu diễn $ f $ sao cho $ D $ có đạo hàm.\n",
    "\n",
    "<div>\n",
    "<img src=\"nn.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Định nghĩa lớp NeuralNetwork\n",
    "- Kế thừa `nn.Module`, khởi tạo ở `__init__()`, định nghĩa `f(x)` ở hàm `forward`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# INSERT CODE HERE\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layer1 = nn.Linear(28*28, 512)\n",
    "        self.hidden1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(512, 512)\n",
    "        self.hidden2 = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.hidden2(x)\n",
    "        out = self.output_layer(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Khởi tạo 1 đối tượng ``NeuralNetwork`` trên ``device``, in ra cấu trúc của nó\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layer1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (hidden1): ReLU()\n",
      "  (layer2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (hidden2): ReLU()\n",
      "  (output_layer): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# INSERT CODE HERE\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sử dụng mô hình `f`: gọi model(x) --> gọi đến hàm foward. **Chú ý:** không gọi trực tiếp ``model.forward()``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0022, -0.0129,  0.0036,  0.0089,  0.0578,  0.0318, -0.0480,  0.0501,\n",
      "         -0.0328,  0.0304]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0989, 0.0978, 0.0994, 0.1000, 0.1050, 0.1023, 0.0944, 0.1042, 0.0959,\n",
      "         0.1021]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "Prediction: tensor([4], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# INSERT CODE HERE\n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "out = model(X)\n",
    "print(out)\n",
    "pred_prob = nn.Softmax(dim=1)(out)\n",
    "print(pred_prob)\n",
    "y_pred = pred_prob.argmax(1)\n",
    "print(\"Prediction: {}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tham số mô hình\n",
    "- Các layer là các hàm với tham số tương ứng, ta cần tìm bộ tham số để tối ưu khoảng cách đã nói ở trên.\n",
    "- Tham số mô hình của NN được gọi là weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layer1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (hidden1): ReLU()\n",
      "  (layer2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (hidden2): ReLU()\n",
      "  (output_layer): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Layer layer1.weight | Size torch.Size([512, 784]) | Values tensor([[ 0.0065, -0.0152,  0.0235,  ..., -0.0170,  0.0135, -0.0188],\n",
      "        [ 0.0083, -0.0191,  0.0325,  ...,  0.0164, -0.0079, -0.0271]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Layer layer1.bias | Size torch.Size([512]) | Values tensor([0.0332, 0.0264], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Layer layer2.weight | Size torch.Size([512, 512]) | Values tensor([[-0.0155,  0.0013, -0.0212,  ..., -0.0172,  0.0082,  0.0199],\n",
      "        [-0.0137, -0.0216, -0.0196,  ..., -0.0424,  0.0050, -0.0171]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Layer layer2.bias | Size torch.Size([512]) | Values tensor([ 0.0216, -0.0423], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Layer output_layer.weight | Size torch.Size([10, 512]) | Values tensor([[-0.0016, -0.0091, -0.0412,  ..., -0.0223,  0.0089, -0.0050],\n",
      "        [ 0.0272,  0.0076,  0.0407,  ..., -0.0334,  0.0383, -0.0344]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Layer output_layer.bias | Size torch.Size([10]) | Values tensor([-0.0117, -0.0385], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "# INSERT CODE HERE\n",
    "print(model)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(\"Layer {} | Size {} | Values {}\".format(name, param.size(), param[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
